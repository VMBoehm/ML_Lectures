{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImprovingVAEs_and_VAEs_on_imperfect_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ6gacjDaHasqFPyphg1zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMBoehm/ML_Lectures/blob/main/ImprovingVAEs_and_VAEs_on_imperfect_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Introduction to Variational AutoEncoders (VAEs) and applications to physical data** "
      ],
      "metadata": {
        "id": "Rvu91ZyEFtBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "by Vanessa Boehm (UC Berkeley and LBNL)   \n",
        "Feb 27 2022"
      ],
      "metadata": {
        "id": "3vg7JmIrF8PD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let' start by importing a few packages, that we will need later"
      ],
      "metadata": {
        "id": "LNZMyGZEuMJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7iquM2NAFde_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RauugG-yVWQu",
        "outputId": "eba89390-e0e9-4261-b670-124098efe2f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this line to confirm the location of your files"
      ],
      "metadata": {
        "id": "1qlleg5Ptwry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls drive/MyDrive/ML_lecture_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYJWjZQ2VqNH",
        "outputId": "208d62a1-291f-45a4-b2e0-3c5230ee30ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder_model_weights.pth\t   Encoder_model_weights.pth\n",
            "DR16_denoised_inpainted.npy\t   VAE\n",
            "DR16_denoised_inpainted_test.npy   VAE_encoder\n",
            "DR16_denoised_inpainted_train.npy  VAE_model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set some immutable variables:\n",
        "The dimensionality of the input data and the dimensionality of the latent (encoded) space"
      ],
      "metadata": {
        "id": "wwlmXPZpxnyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE      = 1000\n",
        "LATENT_SIZE     = 6"
      ],
      "metadata": {
        "id": "mMnt57iDXqIJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create pytorch datasets from the training and test data (note that you need to change the root_dir, if you placed the data in a different folder)"
      ],
      "metadata": {
        "id": "KU4ULbV5x0wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SDSS_DR16(Dataset):\n",
        "    \"\"\"De-redshifted and downsampled spectra from SDSS-BOSS DR16\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir='drive/MyDrive/ML_lecture_data/', transform=True, train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory of data file\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "\n",
        "        if train:\n",
        "            self.data = np.load(open(os.path.join(root_dir,'DR16_denoised_inpainted_train.npy'),'rb'),allow_pickle=True)\n",
        "        else:\n",
        "            self.data = np.load(open(os.path.join(root_dir,'DR16_denoised_inpainted_test.npy'),'rb'),allow_pickle=True)\n",
        "        self.data = torch.as_tensor(self.data)\n",
        "        self.mean = torch.mean(self.data)\n",
        "        self.std  = torch.std(self.data)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        sample = (self.data[idx]-self.mean)/self.std\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "training_data = SDSS_DR16(train=True)\n",
        "test_data     = SDSS_DR16(train=False)"
      ],
      "metadata": {
        "id": "WhaWK_EWF7R_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: Familiarize yourself with torch.distribution.Normal - you can find the documentation here: https://pytorch.org/docs/stable/distributions.html#normal\n",
        "#HINT: It takes a standard deviation (scale) not a variance as input\n",
        "from torch.distributions import Normal as Normal\n",
        "from torch.distributions import MultivariateNormal as MultivariateNormal "
      ],
      "metadata": {
        "id": "s8pX6vYGS0nJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP_Transform(nn.Module):\n",
        "    def __init__(self, binary_mask, dim):\n",
        "        super().__init__()\n",
        "        self.size         = len(binary_mask)\n",
        "        # scale factors\n",
        "        self.mask         =  binary_mask[None,:].float()\n",
        "        self.inverse_mask = (~binary_mask[None,:]).float()\n",
        "        self.dim          = dim\n",
        "        print(self.mask)\n",
        "        # shift factors\n",
        "        self.fc1_s        = torch.nn.Linear(self.size,self.size)\n",
        "        self.fc2_s        = torch.nn.Linear(self.size,self.size)\n",
        "        self.fc1_b        = torch.nn.Linear(self.size,self.size)\n",
        "        self.fc2_b        = torch.nn.Linear(self.size,self.size)\n",
        "\n",
        "\n",
        "    def network_s(self,x):\n",
        "        x = self.fc1_s(x)\n",
        "        x = torch.nn.LeakyReLU()(x)\n",
        "        x = self.fc2_s(x)\n",
        "        x = torch.clip(x,-5,5)\n",
        "        x = x*self.inverse_mask\n",
        "        return x\n",
        "\n",
        "    def network_t(self,x):\n",
        "        x = self.fc1_b(x)\n",
        "        x = torch.nn.LeakyReLU()(x)\n",
        "        x = self.fc1_b(x)\n",
        "        x = x*self.inverse_mask\n",
        "        return x\n",
        "\n",
        "    def forward(self, u):\n",
        "        masked_input = u*self.mask\n",
        "        input        = u*self.inverse_mask\n",
        "        s            = self.network_s(masked_input)\n",
        "        t            = self.network_t(masked_input)\n",
        "        z            = torch.exp(s)*input+t\n",
        "        log_detJ     = torch.sum(s, axis=-1)\n",
        "        z            = self.inverse_mask*z+masked_input\n",
        "        return z, log_detJ\n",
        "\n",
        "    def inverse(self,z):\n",
        "        masked_input = z*self.mask\n",
        "        input        = z*self.inverse_mask\n",
        "        s            = self.network_s(masked_input)\n",
        "        t            = self.network_t(masked_input)\n",
        "        u            = (input-t)/torch.exp(s)\n",
        "        log_detJ_inv = -torch.sum(s,axis=-1)\n",
        "        u            = self.inverse_mask*u+masked_input\n",
        "        return u, log_detJ_inv\n",
        "\n",
        "class FlowModel(nn.Module):\n",
        "    def __init__(self, layers, dim):\n",
        "        super().__init__()\n",
        "        self.dim      = dim\n",
        "        self.layers   = nn.ModuleList(layers)\n",
        "        self.depth    = len(self.layers)\n",
        "        self.p_u      = MultivariateNormal(torch.zeros(self.dim), torch.eye(self.dim))\n",
        "\n",
        "    def forward(self,u):\n",
        "        for ii, layer in enumerate(self.layers):\n",
        "          if ii ==0:\n",
        "            z, det = self.layers[ii].forward(u)\n",
        "          else:\n",
        "            z, det_ = self.layers[ii].forward(z)\n",
        "            det+=det_\n",
        "        return z, det\n",
        "\n",
        "    def inverse(self,z):\n",
        "        for ii in np.arange(self.depth-1,-1,-1):\n",
        "          if ii ==(self.depth-1):\n",
        "            u, inv_det = self.layers[ii].inverse(z)\n",
        "          else:\n",
        "            u, inv_det_ = self.layers[ii].inverse(u)\n",
        "            inv_det+=inv_det_\n",
        "        return u, inv_det\n",
        "\n",
        "    def log_prob(self,z):\n",
        "        shape        = z.shape\n",
        "        z            = z.reshape(-1,self.dim)\n",
        "        u, inv_det = self.inverse(z)\n",
        "        log_prob   = self.p_u.log_prob(u)\n",
        "        log_prob+=inv_det\n",
        "        return log_prob.reshape(shape[:-1])\n",
        "\n",
        "    def rsample(self, N_samples):\n",
        "        u        = self.p_u.rsample(N_samples)\n",
        "        for layer in self.layers:\n",
        "            z, log_det = layer.forward(u)\n",
        "        return z"
      ],
      "metadata": {
        "id": "1dRVbQRlLbUv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NLAYERS = 8\n",
        "masks   = [torch.as_tensor(np.random.rand(LATENT_SIZE)>0.5) for ii in range(NLAYERS)]\n",
        "layers  = [RealNVP_Transform(masks[ii], LATENT_SIZE) for ii in range(NLAYERS)]\n",
        "\n",
        "FM      = FlowModel(layers, LATENT_SIZE)"
      ],
      "metadata": {
        "id": "etj_mu11Qn-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1137dd-125d-4e75-b03e-89db67d1a943"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 1., 1., 0., 1.]])\n",
            "tensor([[0., 0., 0., 1., 1., 1.]])\n",
            "tensor([[1., 0., 0., 1., 1., 1.]])\n",
            "tensor([[1., 1., 0., 0., 1., 0.]])\n",
            "tensor([[1., 0., 1., 0., 1., 1.]])\n",
            "tensor([[1., 0., 1., 0., 0., 1.]])\n",
            "tensor([[1., 0., 0., 0., 0., 1.]])\n",
            "tensor([[0., 0., 1., 1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FM.log_prob(torch.ones(5,10,6)*np.arange(6, dtype=np.float32)[None,None,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfxO1D7C5Jwi",
        "outputId": "05466b46-1c93-4e2b-a5c0-e797de8404ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006,\n",
              "         -15.5006, -15.5006, -15.5006],\n",
              "        [-15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006,\n",
              "         -15.5006, -15.5006, -15.5006],\n",
              "        [-15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006,\n",
              "         -15.5006, -15.5006, -15.5006],\n",
              "        [-15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006,\n",
              "         -15.5006, -15.5006, -15.5006],\n",
              "        [-15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006, -15.5006,\n",
              "         -15.5006, -15.5006, -15.5006]], grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in FM.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKUIvnumuKZ3",
        "outputId": "7976c25d-d3a5-44d2-9a52-7d49f0832c29"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.fc1_s.weight\n",
            "layers.0.fc1_s.bias\n",
            "layers.0.fc2_s.weight\n",
            "layers.0.fc2_s.bias\n",
            "layers.0.fc1_b.weight\n",
            "layers.0.fc1_b.bias\n",
            "layers.0.fc2_b.weight\n",
            "layers.0.fc2_b.bias\n",
            "layers.1.fc1_s.weight\n",
            "layers.1.fc1_s.bias\n",
            "layers.1.fc2_s.weight\n",
            "layers.1.fc2_s.bias\n",
            "layers.1.fc1_b.weight\n",
            "layers.1.fc1_b.bias\n",
            "layers.1.fc2_b.weight\n",
            "layers.1.fc2_b.bias\n",
            "layers.2.fc1_s.weight\n",
            "layers.2.fc1_s.bias\n",
            "layers.2.fc2_s.weight\n",
            "layers.2.fc2_s.bias\n",
            "layers.2.fc1_b.weight\n",
            "layers.2.fc1_b.bias\n",
            "layers.2.fc2_b.weight\n",
            "layers.2.fc2_b.bias\n",
            "layers.3.fc1_s.weight\n",
            "layers.3.fc1_s.bias\n",
            "layers.3.fc2_s.weight\n",
            "layers.3.fc2_s.bias\n",
            "layers.3.fc1_b.weight\n",
            "layers.3.fc1_b.bias\n",
            "layers.3.fc2_b.weight\n",
            "layers.3.fc2_b.bias\n",
            "layers.4.fc1_s.weight\n",
            "layers.4.fc1_s.bias\n",
            "layers.4.fc2_s.weight\n",
            "layers.4.fc2_s.bias\n",
            "layers.4.fc1_b.weight\n",
            "layers.4.fc1_b.bias\n",
            "layers.4.fc2_b.weight\n",
            "layers.4.fc2_b.bias\n",
            "layers.5.fc1_s.weight\n",
            "layers.5.fc1_s.bias\n",
            "layers.5.fc2_s.weight\n",
            "layers.5.fc2_s.bias\n",
            "layers.5.fc1_b.weight\n",
            "layers.5.fc1_b.bias\n",
            "layers.5.fc2_b.weight\n",
            "layers.5.fc2_b.bias\n",
            "layers.6.fc1_s.weight\n",
            "layers.6.fc1_s.bias\n",
            "layers.6.fc2_s.weight\n",
            "layers.6.fc2_s.bias\n",
            "layers.6.fc1_b.weight\n",
            "layers.6.fc1_b.bias\n",
            "layers.6.fc2_b.weight\n",
            "layers.6.fc2_b.bias\n",
            "layers.7.fc1_s.weight\n",
            "layers.7.fc1_s.bias\n",
            "layers.7.fc2_s.weight\n",
            "layers.7.fc2_s.bias\n",
            "layers.7.fc1_b.weight\n",
            "layers.7.fc1_b.bias\n",
            "layers.7.fc2_b.weight\n",
            "layers.7.fc2_b.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell we set the training parameters, define the loss function and create DataLoaders. Pytorch DataLoaders manage the data loading for us (break the dataset into batches, keep track of epochs, reshuffle the data after each epoch) "
      ],
      "metadata": {
        "id": "9KqrUXUY3KW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAEEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, seed=853):\n",
        "        super(VAEEncoder, self).__init__()\n",
        "        # TASK: change the output size of the encoder network. How many parameters must it return to define q(z|x)?\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,LATENT_SIZE*2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TASK: change the output of the encoder network. Instead of just returning z, it should return z and ...?\n",
        "        # HINT: Don't forget that the standard deviation/variance must be strictly positive!\n",
        "        # HINT: You might want to use torch.split()\n",
        "        x      = torch.nn.LeakyReLU()(self.fc1(x))\n",
        "        x      = self.fc2(x)\n",
        "        mu,std = torch.split(x, LATENT_SIZE,dim=-1)\n",
        "        #print(torch.min(mu), torch.max(mu), torch.min(std), torch.max(std))\n",
        "        std    = torch.exp(std) + 1e-8\n",
        "        return mu, std\n"
      ],
      "metadata": {
        "id": "AKMNpHaeb93k"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAEDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, seed=620):\n",
        "        super(VAEDecoder, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(LATENT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,INPUT_SIZE)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.nn.LeakyReLU()(self.fc1(z))\n",
        "        x = self.fc2(z)\n",
        "        return x"
      ],
      "metadata": {
        "id": "t-_V5PYNMNSy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    #TASK: add parameters mentioned in point 1. \n",
        "    def __init__(self, sample_size, sigma):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VAEEncoder()\n",
        "        self.decoder = VAEDecoder()\n",
        "        self.sample_size = sample_size\n",
        "        self.sigma       = sigma\n",
        "        #TASK: Use the Normal class to define the prior (a standard normal distribution), p(z)\n",
        "        self.prior       = FlowModel(layers, LATENT_SIZE)\n",
        "\n",
        "    def change_sample_size(self,sample_size):\n",
        "        self.sample_size = sample_size\n",
        "        return True\n",
        "\n",
        "    def get_q(self,x):\n",
        "        #TASK: write a method that computes q(z,x)\n",
        "        #HINT: use the Normal class we imported above\n",
        "        mu, std = self.encoder(x)\n",
        "        self.q  = Normal(mu, std)\n",
        "        return True\n",
        "\n",
        "    def sample_q(self):\n",
        "        #TASK: write a method that samples from q\n",
        "        #HINT: use rsample to apply the reparameterization trick\n",
        "        z_sample = self.q.rsample(torch.Size([self.sample_size]))\n",
        "        #z_sample = torch.reshape(z_sample,[-1,LATENT_SIZE])\n",
        "        #print(z_sample.shape)\n",
        "        return z_sample\n",
        "\n",
        "    def get_avg_log_likelihood(self,recons,x):\n",
        "        #TASK: Write a method that returns the first term in the ELBO (this method should define the likelihood and evaluate the average log likelihood of the reconstruction)\n",
        "        #HINT: Pay attention to shapes. The function should return an average log likelihood (a single number) for every data point in the batch.\n",
        "        #HINT: The output shape of Normal(mu, sigma).log_prob() is a little unintuitive. If mu or sigma are N-dimensional, it returns N results (applies N independent Gaussians). \n",
        "        #HINT: You need to average over samples from q to obtain the final result.\n",
        "        ll    = Normal(x[None,:,:], self.sigma)\n",
        "        log_p = ll.log_prob(recons)\n",
        "        log_p = torch.sum(log_p,dim=-1)\n",
        "        return torch.mean(log_p,dim=0)\n",
        "\n",
        "    def stochastic_kl_divergence(self,z_sample):\n",
        "        #print(self.q.log_prob(z_sample).shape,self.prior.log_prob(z_sample).shape)\n",
        "        #TASK: write a method that computes the kl-divergence between q(z|x) and p(z) \n",
        "        return torch.mean(torch.sum(self.q.log_prob(z_sample),dim=-1)-self.prior.log_prob(z_sample), dim=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TASK: a forward pass should return the two terms in the ELBO\n",
        "        #HINT: use all methods we defined above\n",
        "        self.get_q(x)\n",
        "        samples = self.sample_q()\n",
        "        recons  = self.decoder(samples)\n",
        "        log_likelihood = self.get_avg_log_likelihood(recons,x)\n",
        "        kl      = self.stochastic_kl_divergence(samples)\n",
        "        return log_likelihood, kl"
      ],
      "metadata": {
        "id": "IblX0IgkbcMI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 3**: Prepare for training"
      ],
      "metadata": {
        "id": "Ox7VgW-R6W6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE       = 128\n",
        "BATCHSIZE_TEST  = 128\n",
        "LEARNING_RATE   = 1e-3\n",
        "\n",
        "\n",
        "#TASK: create an instance of the Variational Autoencoder\n",
        "VAE = VariationalAutoencoder(sample_size=16,sigma=0.01)\n",
        "\n",
        "optimizer = torch.optim.Adam(VAE.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "\n",
        "# Dataloaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCHSIZE, shuffle=True)\n",
        "test_dataloader  = DataLoader(test_data, batch_size=BATCHSIZE_TEST, shuffle=True)"
      ],
      "metadata": {
        "id": "2DYaUij-WkK3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for name, param in VAE.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCj2DIpVu7xk",
        "outputId": "a336bdba-5314-4e43-c267-24421b676b1d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.fc1.weight\n",
            "encoder.fc1.bias\n",
            "encoder.fc2.weight\n",
            "encoder.fc2.bias\n",
            "decoder.fc1.weight\n",
            "decoder.fc1.bias\n",
            "decoder.fc2.weight\n",
            "decoder.fc2.bias\n",
            "prior.layers.0.fc1_s.weight\n",
            "prior.layers.0.fc1_s.bias\n",
            "prior.layers.0.fc2_s.weight\n",
            "prior.layers.0.fc2_s.bias\n",
            "prior.layers.0.fc1_b.weight\n",
            "prior.layers.0.fc1_b.bias\n",
            "prior.layers.0.fc2_b.weight\n",
            "prior.layers.0.fc2_b.bias\n",
            "prior.layers.1.fc1_s.weight\n",
            "prior.layers.1.fc1_s.bias\n",
            "prior.layers.1.fc2_s.weight\n",
            "prior.layers.1.fc2_s.bias\n",
            "prior.layers.1.fc1_b.weight\n",
            "prior.layers.1.fc1_b.bias\n",
            "prior.layers.1.fc2_b.weight\n",
            "prior.layers.1.fc2_b.bias\n",
            "prior.layers.2.fc1_s.weight\n",
            "prior.layers.2.fc1_s.bias\n",
            "prior.layers.2.fc2_s.weight\n",
            "prior.layers.2.fc2_s.bias\n",
            "prior.layers.2.fc1_b.weight\n",
            "prior.layers.2.fc1_b.bias\n",
            "prior.layers.2.fc2_b.weight\n",
            "prior.layers.2.fc2_b.bias\n",
            "prior.layers.3.fc1_s.weight\n",
            "prior.layers.3.fc1_s.bias\n",
            "prior.layers.3.fc2_s.weight\n",
            "prior.layers.3.fc2_s.bias\n",
            "prior.layers.3.fc1_b.weight\n",
            "prior.layers.3.fc1_b.bias\n",
            "prior.layers.3.fc2_b.weight\n",
            "prior.layers.3.fc2_b.bias\n",
            "prior.layers.4.fc1_s.weight\n",
            "prior.layers.4.fc1_s.bias\n",
            "prior.layers.4.fc2_s.weight\n",
            "prior.layers.4.fc2_s.bias\n",
            "prior.layers.4.fc1_b.weight\n",
            "prior.layers.4.fc1_b.bias\n",
            "prior.layers.4.fc2_b.weight\n",
            "prior.layers.4.fc2_b.bias\n",
            "prior.layers.5.fc1_s.weight\n",
            "prior.layers.5.fc1_s.bias\n",
            "prior.layers.5.fc2_s.weight\n",
            "prior.layers.5.fc2_s.bias\n",
            "prior.layers.5.fc1_b.weight\n",
            "prior.layers.5.fc1_b.bias\n",
            "prior.layers.5.fc2_b.weight\n",
            "prior.layers.5.fc2_b.bias\n",
            "prior.layers.6.fc1_s.weight\n",
            "prior.layers.6.fc1_s.bias\n",
            "prior.layers.6.fc2_s.weight\n",
            "prior.layers.6.fc2_s.bias\n",
            "prior.layers.6.fc1_b.weight\n",
            "prior.layers.6.fc1_b.bias\n",
            "prior.layers.6.fc2_b.weight\n",
            "prior.layers.6.fc2_b.bias\n",
            "prior.layers.7.fc1_s.weight\n",
            "prior.layers.7.fc1_s.bias\n",
            "prior.layers.7.fc2_s.weight\n",
            "prior.layers.7.fc2_s.bias\n",
            "prior.layers.7.fc1_b.weight\n",
            "prior.layers.7.fc1_b.bias\n",
            "prior.layers.7.fc2_b.weight\n",
            "prior.layers.7.fc2_b.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in FM.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqSs4NRNCRWz",
        "outputId": "398c2e12-3f40-4d05-ed7f-1e688112ae0f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.fc1_s.weight\n",
            "layers.0.fc1_s.bias\n",
            "layers.0.fc2_s.weight\n",
            "layers.0.fc2_s.bias\n",
            "layers.0.fc1_b.weight\n",
            "layers.0.fc1_b.bias\n",
            "layers.0.fc2_b.weight\n",
            "layers.0.fc2_b.bias\n",
            "layers.1.fc1_s.weight\n",
            "layers.1.fc1_s.bias\n",
            "layers.1.fc2_s.weight\n",
            "layers.1.fc2_s.bias\n",
            "layers.1.fc1_b.weight\n",
            "layers.1.fc1_b.bias\n",
            "layers.1.fc2_b.weight\n",
            "layers.1.fc2_b.bias\n",
            "layers.2.fc1_s.weight\n",
            "layers.2.fc1_s.bias\n",
            "layers.2.fc2_s.weight\n",
            "layers.2.fc2_s.bias\n",
            "layers.2.fc1_b.weight\n",
            "layers.2.fc1_b.bias\n",
            "layers.2.fc2_b.weight\n",
            "layers.2.fc2_b.bias\n",
            "layers.3.fc1_s.weight\n",
            "layers.3.fc1_s.bias\n",
            "layers.3.fc2_s.weight\n",
            "layers.3.fc2_s.bias\n",
            "layers.3.fc1_b.weight\n",
            "layers.3.fc1_b.bias\n",
            "layers.3.fc2_b.weight\n",
            "layers.3.fc2_b.bias\n",
            "layers.4.fc1_s.weight\n",
            "layers.4.fc1_s.bias\n",
            "layers.4.fc2_s.weight\n",
            "layers.4.fc2_s.bias\n",
            "layers.4.fc1_b.weight\n",
            "layers.4.fc1_b.bias\n",
            "layers.4.fc2_b.weight\n",
            "layers.4.fc2_b.bias\n",
            "layers.5.fc1_s.weight\n",
            "layers.5.fc1_s.bias\n",
            "layers.5.fc2_s.weight\n",
            "layers.5.fc2_s.bias\n",
            "layers.5.fc1_b.weight\n",
            "layers.5.fc1_b.bias\n",
            "layers.5.fc2_b.weight\n",
            "layers.5.fc2_b.bias\n",
            "layers.6.fc1_s.weight\n",
            "layers.6.fc1_s.bias\n",
            "layers.6.fc2_s.weight\n",
            "layers.6.fc2_s.bias\n",
            "layers.6.fc1_b.weight\n",
            "layers.6.fc1_b.bias\n",
            "layers.6.fc2_b.weight\n",
            "layers.6.fc2_b.bias\n",
            "layers.7.fc1_s.weight\n",
            "layers.7.fc1_s.bias\n",
            "layers.7.fc2_s.weight\n",
            "layers.7.fc2_s.bias\n",
            "layers.7.fc1_b.weight\n",
            "layers.7.fc1_b.bias\n",
            "layers.7.fc2_b.weight\n",
            "layers.7.fc2_b.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: define the new loss function\n",
        "def negative_ELBO(avg_log_likelihood,kl):\n",
        "\n",
        "    negative_ELBO = - torch.mean(avg_log_likelihood-kl)\n",
        "\n",
        "    return negative_ELBO"
      ],
      "metadata": {
        "id": "zw8MYTJWW4N8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    losses = []\n",
        "    for batch, X in enumerate(dataloader):\n",
        "        #TASK: compute the loss from the output of the VAE foward pass  \n",
        "        log_likelihood, kl = model(X)\n",
        "        loss = loss_fn(log_likelihood,kl)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0, norm_type=2)\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            losses.append(loss)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        #assert(False)\n",
        "\n",
        "    #scheduler.step()\n",
        "    return losses\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, nllh, kl_ = 0, 0, 0\n",
        "    #model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X in dataloader:\n",
        "            #TASK: in the test loop we want to keep track not only of the ELBO, but also of the two terms that contribute to the ELBO (kl diveregence and loglikelihood)\n",
        "            log_likelihood, kl = model(X)\n",
        "            test_loss += loss_fn(log_likelihood,kl).item()\n",
        "            nllh += -np.mean(log_likelihood.cpu().numpy())\n",
        "            kl_ += np.mean(kl.cpu().numpy())\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    kl_ /= num_batches\n",
        "    nllh /= num_batches\n",
        "\n",
        "    print(f\" Avg test loss      : {test_loss:>8f}\")\n",
        "    print(f\" Avg KL             : {kl_:>8f}\")\n",
        "    print(f\" Avg negative log likelihood : {nllh:>8f} \\n\")\n",
        "\n",
        "    return test_loss, kl_, nllh\n"
      ],
      "metadata": {
        "id": "0yjd0yE4WrKc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train!"
      ],
      "metadata": {
        "id": "uZMlhzGoYJvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "train_loss = []\n",
        "test_loss  = []\n",
        "for t in range(EPOCHS):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss.append(train_loop(train_dataloader, VAE, negative_ELBO, optimizer))\n",
        "    test_loss.append(test_loop(test_dataloader, VAE, negative_ELBO))\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Udr9UnLXmJf",
        "outputId": "cab47b34-dd58-43a3-cb4b-f0ef5ec4d759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4545454.000000  [    0/100000]\n",
            "loss: 67032.773438  [12800/100000]\n",
            "loss: 47903.929688  [25600/100000]\n",
            "loss: 16856.562500  [38400/100000]\n",
            "loss: 82098.984375  [51200/100000]\n",
            "loss: 10391.562500  [64000/100000]\n",
            "loss: 24584.082031  [76800/100000]\n",
            "loss: 18561.988281  [89600/100000]\n",
            " Avg test loss      : 27260.736438\n",
            " Avg KL             : 43.103584\n",
            " Avg negative log likelihood : 27217.633216 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 18185.970703  [    0/100000]\n",
            "loss: 20075.046875  [12800/100000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss=np.asarray(test_loss)"
      ],
      "metadata": {
        "id": "yXZtkOVVFuNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: plot the training loss, test loss, and the contributions to teh loss from each of the two terms \n",
        "length = len(np.asarray(train_loss).flatten())\n",
        "plt.figure()\n",
        "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
        "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,0],label='test set loss')\n",
        "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,1],label='test set kl')\n",
        "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss[:,2],label='test set neg log likelihood')\n",
        "plt.xlabel('training step')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(np.min(train_loss),15000)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7syew_eAXpfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK: Inspect how the contribution of the kl divergence and log likelihood to the loss change as you change the noise in the likelihood. Some suggested values: sigma=[0.5,1,2]\n",
        "# TASK: what ahppens if you change the number of samples?\n",
        "# What do you observe? Can you interpret it?"
      ],
      "metadata": {
        "id": "U0tcAyjRaZ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 4:** Inspect the model performance\n",
        "\n",
        "Similar to the AE, we will look at the average reconstruction quality. But in addition, we also want to know how well the kl term was minimized. We will therefore look at three things\n",
        "\n",
        "1.   Reconstruction quality\n",
        "2.   Scatter plots of posterior samples and prior samples. Recall that $p(z)=\\int \\mathcal{d}x\\, p(x,z) \\approx \\frac{1}{N_{samples}} \\sum_{x\\sim p(x)} p(z|x)$.\n",
        "3.   Quality of artificial data generation\n"
      ],
      "metadata": {
        "id": "Y6RbwE2BXxrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the mapping from pixel to the de-redshifted (rest) wavelength\n",
        "wlmin, wlmax      = (3388,8318)\n",
        "fixed_num_bins    = 1000\n",
        "wl_range          = (np.log10(wlmin),np.log10(wlmax))\n",
        "wl                = np.logspace(wl_range[0],wl_range[1],fixed_num_bins) \n",
        " \n",
        " #TASK: plot the average reconstruction error of the model as a function of wavelength (similar to above). How does it compare to the Autoencoder?\n",
        " #HINT: Use the mean of $q(z|x)$ as the latent point for data x\n",
        "avg_loss  = 0\n",
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "    for X in test_dataloader:\n",
        "        pred = VAE.decoder(VAE.encoder(X)[0])\n",
        "        avg_loss+=np.mean((pred.cpu().numpy()-X.cpu().numpy())**2,axis=0)/(len(test_data)//BATCHSIZE_TEST)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(wl, np.sqrt(avg_loss))\n",
        "plt.ylabel('average reconstruction error')\n",
        "plt.xlabel('wavelength [Ångströms]')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OvdilGwgXmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: make a corner plot of posterior samples. Does the average posterior match the prior?\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "    for ii, X in enumerate(test_dataloader):\n",
        "        VAE.get_q(X)\n",
        "        prior_sample = VAE.prior.rsample([BATCHSIZE_TEST])\n",
        "        sample       = VAE.sample_q().cpu().numpy()[0:1].swapaxes(0,1)\n",
        "        if ii==0:\n",
        "          samples       = sample\n",
        "          prior_samples = prior_sample\n",
        "        else:\n",
        "          samples       = np.vstack([samples, sample])\n",
        "          prior_samples = np.vstack([prior_samples, prior_sample])\n",
        "\n",
        "samples       = np.reshape(samples,[-1, LATENT_SIZE])\n",
        "prior_samples = np.reshape(prior_samples,[-1, LATENT_SIZE])\n",
        "\n",
        "print(samples.shape)\n",
        "print(prior_samples.shape)\n",
        "\n",
        "data1    = pd.DataFrame()\n",
        "data2    = pd.DataFrame()\n",
        "\n",
        "for ii in range(LATENT_SIZE):\n",
        "  data1['dim_%d'%ii] = samples[:,ii]\n",
        "data1['source'] = 'posterior'\n",
        "\n",
        "for ii in range(LATENT_SIZE):\n",
        "  data2['dim_%d'%ii] = prior_samples[:,ii]\n",
        "data2['source'] = 'prior'\n",
        "\n",
        "data = pd.concat([data2,data1]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "#HINT: to get a density estimate you can set kind='kde', but you'll probably have to reduce the number of samples, or try 'hist' instead\n",
        "sns.pairplot(data,corner=True,kind='scatter', hue='source', plot_kws={'s':4})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9zbCDqW93Vwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: Generate artificial data: sample from the prior and foward model the sample thorugh the decoder. Do the samples look realistic? Why?/Why not?"
      ],
      "metadata": {
        "id": "62rkkkwbewKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "  samples = VAE.prior.rsample([16])\n",
        "  data_samples = VAE.decoder(samples)\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(4,4, figsize=(20,10), sharex=True)\n",
        "ax = ax.flatten()\n",
        "for ii in range(16):\n",
        "  ax[ii].plot(wl,data_samples[ii], label='artificial data')\n",
        "  if ii in np.arange(12,16):\n",
        "    ax[ii].set_xlabel('wavelength [Ångströms]')\n",
        "  if ii in [0,4,8,12]:\n",
        "    ax[ii].set_ylabel('some standardized flux')\n",
        "  if ii==0:\n",
        "    ax[ii].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YhYlgfZLm_iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DUFvwefkG0Mr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}